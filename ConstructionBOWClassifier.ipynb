{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from string import punctuation\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "stemmer = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data helpers\n",
    "\n",
    "class ContstructionData:\n",
    "    def __init__(self):\n",
    "        self.training_data = [\n",
    "            {\"label\":\"Concrete\", \"sentence\":\"Please indicate which concrete elements get a smooth formed and rubbed finish.\"},\n",
    "            {\"label\":\"Concrete\", \"sentence\":\"A note in concrete section of general construction notes indicates slump to be 4\\\" where specification in concrete section says 5\\\" slump. Please verify\"},\n",
    "            {\"label\":\"Concrete\", \"sentence\":\"Need demensions and specs for the precast slab cement work and what moulde type\"},\n",
    "            {\"label\":\"Concrete\", \"sentence\":\"How much Slab should we pour?\"},\n",
    "            {\"label\":\"Concrete\", \"sentence\":\"Please specify the flooring underlay or cementious underlayments\"},\n",
    "            {\"label\":\"Concrete\", \"sentence\":\"Specify cast-in-place mix and quantity for transport\"},\n",
    "            {\"label\":\"Concrete\", \"sentence\":\"Provide concrete haunch for the sidewalk slab to acheive the finish grade elevations shown in the plans. Account for theoretical deflections due to self weight, pavers, slab forming systems, etc. as required\"},\n",
    "            {\"label\":\"Concrete\", \"sentence\":\"see attached plan sheet and picture of the crack in the concrete that has occurred in 3 different locations as discussed at the monthly meeting. I am concerned these cracks will get worse once the freezer is in operation. Please advise how to repair\"},\n",
    "            {\"label\":\"Concrete\", \"sentence\":\"subcontractor would like to pour the slab and then epoxy in the rebar to ensure the rebar is placed in an accurate position. Please confirm that this is acceptable using Retrofit XP Epoxy\"},\n",
    "            {\"label\":\"Concrete\", \"sentence\":\"Drawing 5 indicates that Concrete in Structures, Slab‐on‐Grade is to be used. Please advise which Class of concrete should be used for Concrete in Structures, Slab‐on‐Grade.\"},\n",
    "            {\"label\":\"Concrete\", \"sentence\":\"Should we bolt items to concrete inserts and structural elements?\"},\n",
    "            {\"label\":\"Concrete\", \"sentence\":\"Can we use crushed concrete\"},\n",
    "            {\"label\":\"Concrete\", \"sentence\":\"should we use a cement underlayment to level the floor\"},\n",
    "            {\"label\":\"Electrical\", \"sentence\":\"It was noted that the vanity lights were left off of the drawings in some locations and shown incorrectly in others.\"},\n",
    "            {\"label\":\"Electrical\", \"sentence\":\"What lighting fixtures do you want?\"},\n",
    "            {\"label\":\"Electrical\", \"sentence\":\"need to rework electric blueprint\"},\n",
    "            {\"label\":\"Electrical\", \"sentence\":\"what type of light bulbs do you want\"},\n",
    "            {\"label\":\"Electrical\", \"sentence\":\"Should we use metal barriers to separate wiring of different systems and voltage\"},\n",
    "            {\"label\":\"Electrical\", \"sentence\":\"Will lighting be required on the temporary bridge? Will permanent lighting be required in the Park?\"},\n",
    "            {\"label\":\"Electrical\", \"sentence\":\"Drawing 505 calls for fiber optic cable to be run from IT closet 106 to (2) other racks but does not tell us how many strands to include. Please clarify how many strands each cable should be\"},\n",
    "            {\"label\":\"Electrical\", \"sentence\":\"Drawing 505 calls for LC fiber connectors, but the specifications call for SC connectors. Please clarify which is correct\"},\n",
    "            {\"label\":\"Electrical\", \"sentence\":\"Indicate the available fault current and ampacity interrupting capacity for all switchboards, distribution boards, panelboards, transfer switches, enclosed circuit breakers, motor control centers, VFDs\"},\n",
    "            {\"label\":\"Electrical\", \"sentence\":\"Please confirm that all pedestrian post top light fixtures, parking lot light fixtures, and roadway light fixtures shall be individually fused\"},\n",
    "            {\"label\":\"Electrical\", \"sentence\":\"Please provide protective barriers around primary switchgear (Vacuum switches and PMH switchgear), transformers, electrical and communications manholes\"},\n",
    "            {\"label\":\"Electrical\", \"sentence\":\"need to repair power distribution systems and components, please advice\"},\n",
    "            {\"label\":\"Electrical\", \"sentence\":\"underground wiring needs rework\"},\n",
    "            {\"label\":\"Finishes\", \"sentence\":\"Need to know paint color\"},\n",
    "            {\"label\":\"Finishes\", \"sentence\":\"It appears that there are numerous locations where the existing painted surfaces have failed, resulting in rustication, and in some cases rot. In order to prevent further failure of these surfaces, we are recommending complete removal of the existing paint to bare steel, and then proceed with metal primer and finish coats\"},\n",
    "            {\"label\":\"Finishes\", \"sentence\":\"can you specify if you want tile or carpet or wood flooring and what type\"},\n",
    "            {\"label\":\"Finishes\", \"sentence\":\"how much wallpaper for the wall and what design and what color\"},\n",
    "            {\"label\":\"Finishes\", \"sentence\":\"please specify Terrazzo quartz or granite chips before it is cured and how many polish coats\"},\n",
    "            {\"label\":\"Finishes\", \"sentence\":\"Spec Section 123 Does not have a Paint product listed for the exposed metal deck, trusses, conduit, ductwork. What is the paint product for the Hollow metal doors and frames?\"},\n",
    "            {\"label\":\"Finishes\", \"sentence\":\"Are we to assume painting this screen?\"},\n",
    "            {\"label\":\"Finishes\", \"sentence\":\"what color should we paint the bathroom\"},\n",
    "            {\"label\":\"Finishes\", \"sentence\":\"what shade of blue and green do you prefer\"},\n",
    "            {\"label\":\"Finishes\", \"sentence\":\"please provide tile type and color and design for the kitchen surfaces\"},\n",
    "            {\"label\":\"Finishes\", \"sentence\":\"do you want a gypsum wallboard\"},\n",
    "            {\"label\":\"Finishes\", \"sentence\":\"do you want laminate flooring or ceramic tiles\"},\n",
    "            {\"label\":\"Masonry\", \"sentence\":\"What is the dimension of the brick that returns North and terminates into the Type A Metal Panel?\"},\n",
    "            {\"label\":\"Masonry\", \"sentence\":\"Verify cut masonry brick veneer and cmu (concrete masonry units)\"},\n",
    "            {\"label\":\"Masonry\", \"sentence\":\"Should bullnose type concrete masonry units be used at all edges and exterior corners?\"},\n",
    "            {\"label\":\"Masonry\", \"sentence\":\"Please specify mortar for base of brick\"},\n",
    "            {\"label\":\"Masonry\", \"sentence\":\"Please advise - Exterior masonry wall not structurally sound, biggest concern is the structural adequacy of the existing clay tile wall that they would like us to anchor our face brick to\"},\n",
    "            {\"label\":\"Masonry\", \"sentence\":\"can we screw masonry ties into this wall for our face brick?\"},\n",
    "            {\"label\":\"Masonry\", \"sentence\":\"Should we provide CMU back-up? Can we use existing masonry anchors or provide new anchors? Can we reconstruct existing brick veneer?\"},\n",
    "            {\"label\":\"Masonry\", \"sentence\":\"Please provide stone type cut and color\"},\n",
    "            {\"label\":\"Masonry\", \"sentence\":\"need natural stone and mortar to make load-bearing and non-bearing walls\"},\n",
    "            {\"label\":\"Masonry\", \"sentence\":\"brickwork needs to be redone, please advise\"},\n",
    "            {\"label\":\"Masonry\", \"sentence\":\"clarify fired clay brick or stone masonry for the wall material\"},\n",
    "            {\"label\":\"Masonry\", \"sentence\":\"quantity needed for heavy sliced stone roofing\"},\n",
    "            {\"label\":\"Masonry\", \"sentence\":\"clarify if this should be a dry stonewall or a stonewall with mortar, and if so, please specify mortar\"},\n",
    "            {\"label\":\"Masonry\", \"sentence\":\"we need more stone for the gravel path, please approve\"},\n",
    "            {\"label\":\"Masonry\", \"sentence\":\"The bricks are cracked and need to be replaced, please advise\"},\n",
    "        ]\n",
    "        self.testing_data = [\n",
    "            {\"label\": \"Concrete\", \"sentence\": \"need specs on concrete slab\"},\n",
    "            {\"label\": \"Electrical\", \"sentence\": \"cabling details needed\"},\n",
    "            {\"label\": \"Finishes\", \"sentence\": \"how many coats of primer and red do you want?\"}\n",
    "        ]\n",
    "        #print (\"%s sentences in training data\" % len(self.training_data))\n",
    "        #print (\"%s sentences in testing data\" % len(self.testing_data))\n",
    "    \n",
    "    \n",
    "    # ### Refactor to load from file ###\n",
    "    \n",
    "    @classmethod\n",
    "    def load_training_data(self):\n",
    "        return ContstructionData().training_data\n",
    "    \n",
    "    @classmethod\n",
    "    def load_testing_data(self):\n",
    "        return ContstructionData().testing_data\n",
    "    \n",
    "\n",
    "training_set = ContstructionData.load_training_data()\n",
    "testing_set = ContstructionData.load_testing_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 documents\n",
      "4 classes ['Concrete', 'Electrical', 'Finishes', 'Masonry']\n",
      "468 unique stemmed words ['pleas', 'ind', 'concret', 'el', 'smoo', 'form', 'rub', 'fin', 'not', 'concret', 'sect', 'gen', 'construct', 'not', 'ind', 'slump', 'spec', 'concret', 'sect', 'say', 'slump', 'pleas', 'ver', 'nee', 'demend', 'spec', 'precast', 'slab', 'cem', 'mould', 'typ', 'how', 'slab', 'pour', 'pleas', 'spec', 'flo', 'underlay', 'cementy', 'underlay', 'spec', 'castinplac', 'mix', 'quant', 'transport', 'provid', 'concret', 'haunch', 'sidewalk', 'slab', 'acheiv', 'fin', 'grad', 'elev', 'plan', 'account', 'theoret', 'deflect', 'weight', 'pav', 'slab', 'form', 'system', 'requir', 'attach', 'plan', 'sheet', 'pict', 'crack', 'concret', 'occur', 'diff', 'loc', 'discuss', 'month', 'meet', 'concern', 'crack', 'wors', 'freez', 'op', 'pleas', 'adv', 'repair', 'subcontract', 'lik', 'pour', 'slab', 'epoxy', 'reb', 'ens', 'reb', 'plac', 'acc', 'posit', 'pleas', 'acceiv', 'retrofit', 'xp', 'epoxy', 'draw', 'ind', 'concret', 'structures', 'pleas', 'adv', 'class', 'concret', 'concret', 'structures', 'should', 'bolt', 'item', 'concret', 'insert', 'structural', 'el', 'crush', 'concret', 'cem', 'underlay', 'level', 'flo', 'it', 'not', 'van', 'light', 'left', 'draw', 'loc', 'incorrect', 'oth', 'what', 'light', 'fixt', 'nee', 'elect', 'blueprint', 'typ', 'light', 'bulb', 'should', 'met', 'barry', 'sep', 'wir', 'diff', 'system', 'volt', 'wil', 'light', 'requir', 'temp', 'bridg', 'wil', 'perm', 'light', 'requir', 'park', 'draw', 'cal', 'fib', 'opt', 'cabl', 'run', 'it', 'closet', 'rack', 'tel', 'strands', 'includ', 'pleas', 'clar', 'strands', 'cabl', 'draw', 'cal', 'lc', 'fib', 'connect', 'spec', 'cal', 'sc', 'connect', 'pleas', 'clar', 'ind', 'avail', 'fault', 'cur', 'ampac', 'interrupt', 'capac', 'switchboard', 'distribut', 'board', 'panelboard', 'transf', 'switch', 'enclos', 'circuit', 'break', 'mot', 'control', 'cent', 'vfds', 'pleas', 'pedest', 'post', 'top', 'light', 'fixt', 'park', 'lot', 'light', 'fixt', 'roadway', 'light', 'fixt', 'shal', 'individ', 'fus', 'pleas', 'provid', 'protect', 'barry', 'around', 'prim', 'switchgear', 'vacu', 'switch', 'pmh', 'switchgear', 'transform', 'elect', 'commun', 'manhol', 'nee', 'repair', 'pow', 'distribut', 'system', 'compon', 'pleas', 'adv', 'underground', 'wir', 'nee', 'nee', 'paint', 'col', 'it', 'appear', 'num', 'loc', 'ex', 'paint', 'surfac', 'fail', 'result', 'rust', 'cas', 'rot', 'in', 'ord', 'prev', 'fail', 'surfac', 'recommend', 'complet', 'remov', 'ex', 'paint', 'bar', 'steel', 'process', 'met', 'prim', 'fin', 'coat', 'spec', 'til', 'carpet', 'wood', 'flo', 'typ', 'wallpap', 'wal', 'design', 'col', 'pleas', 'spec', 'terrazzo', 'quartz', 'granit', 'chip', 'cur', 'pol', 'coat', 'spec', 'sect', 'doe', 'paint', 'produc', 'list', 'expos', 'met', 'deck', 'truss', 'conduit', 'ductwork', 'what', 'paint', 'produc', 'hollow', 'met', 'door', 'fram', 'ar', 'assum', 'paint', 'screen', 'col', 'paint', 'bathroom', 'shad', 'blu', 'green', 'pref', 'pleas', 'provid', 'til', 'typ', 'col', 'design', 'kitch', 'surfac', 'gyps', 'wallboard', 'lamin', 'flo', 'ceram', 'til', 'what', 'dimend', 'brick', 'return', 'nor', 'termin', 'typ', 'met', 'panel', 'ver', 'cut', 'masonry', 'brick', 'ven', 'cmu', 'concret', 'masonry', 'unit', 'should', 'bullnos', 'typ', 'concret', 'masonry', 'unit', 'edg', 'extery', 'corn', 'pleas', 'spec', 'mort', 'bas', 'brick', 'pleas', 'adv', 'extery', 'masonry', 'wal', 'structurally', 'sound', 'biggest', 'concern', 'structural', 'adequ', 'ex', 'clay', 'til', 'wal', 'lik', 'anch', 'fac', 'brick', 'screw', 'masonry', 'tie', 'wal', 'fac', 'brick', 'should', 'provid', 'cmu', 'backup', 'ex', 'masonry', 'anch', 'provid', 'new', 'anch', 'reconstruct', 'ex', 'brick', 'ven', 'pleas', 'provid', 'ston', 'typ', 'cut', 'col', 'nee', 'nat', 'ston', 'mort', 'mak', 'loadbear', 'nonbear', 'wal', 'brickwork', 'nee', 'redon', 'pleas', 'adv', 'clar', 'fir', 'clay', 'brick', 'ston', 'masonry', 'wal', 'mat', 'quant', 'nee', 'heavy', 'slic', 'ston', 'roof', 'clar', 'dry', 'stonewal', 'stonewal', 'mort', 'pleas', 'spec', 'mort', 'nee', 'ston', 'gravel', 'path', 'pleas', 'approv', 'the', 'brick', 'crack', 'nee', 'replac', 'pleas', 'adv']\n",
      "# words 468\n",
      "# classes 4\n",
      "[0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Process input and output data\n",
    "# Filter out punctuation, stopwords, numbers, etc\n",
    "\n",
    "words = []\n",
    "classes = []\n",
    "documents = []\n",
    "\n",
    "# common words that are unnecessary to classify the text\n",
    "ignore_words = ['note', 'noted', 'notes', 'see', 'attached', 'need', 'needed', 'can', 'please', 'verify', 'clarify', 'specify', 'provide', 'us', 'want', 'confirm', 'would', 'know', 'says', 'assume', 'indicate', 'like', 'get', 'etc', 'rework', 'used', 'use', 'due', 'self', 'much', 'work', 'correct', 'worse', 'discussed', 'monthly', 'approve', 'make', 'many', 'shown']\n",
    "\n",
    "def process_sentence(text):\n",
    "    # create array of words\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # remove punctuation\n",
    "    table = str.maketrans('', '', punctuation)\n",
    "    tokens = [word.translate(table) for word in tokens]\n",
    "    # remove stopwords, ex: a, if, to, or\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    # remove numbers\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # remove short tokens\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    # lowercase words and stem, ex: this is so walker and and walking map the same way\n",
    "    tokens = [stemmer.stem(word.lower()) for word in tokens]\n",
    "    tokens = [word for word in tokens if word not in ignore_words]\n",
    "    return tokens\n",
    "\n",
    "def process_data(dataset, word_list, label_list, doc):\n",
    "    for pattern in dataset:\n",
    "        words_array = process_sentence(pattern['sentence'])\n",
    "        word_list.extend(words_array)\n",
    "        doc.append((words_array, pattern['label']))\n",
    "        if pattern['label'] not in label_list:\n",
    "            label_list.append(pattern['label'])\n",
    "    \n",
    "    # remove duplicates\n",
    "    words = list(set(word_list))\n",
    "    classes = list(set(label_list))\n",
    "\n",
    "\n",
    "# Preprocess to have list of words and classes\n",
    "process_data(training_set, words, classes, documents)\n",
    "\n",
    "print (len(documents), \"documents\")\n",
    "print (len(classes), \"classes\", classes)\n",
    "print (len(words), \"unique stemmed words\", words)\n",
    "\n",
    "\n",
    "# Create Training Data\n",
    "# Now translate training data into numbers so our neural network can train on this input\n",
    "# Input will be converted into a list of 1's or 0's, where 1 indicates the existence of a word as it maps to the words list\n",
    "\n",
    "training = []\n",
    "output = []\n",
    "# create an empty array for our output\n",
    "output_empty = [0] * len(classes)\n",
    "\n",
    "# training set, bag of words for each sentence\n",
    "for doc in documents:\n",
    "    # initialize our bag of words, doc[0] is sentence, doc[1] is class name\n",
    "    bag = []\n",
    "    pattern_words = doc[0]\n",
    "    # stem each word\n",
    "    pattern_words = [stemmer.stem(word.lower()) for word in pattern_words]\n",
    "    # create our bag of words array\n",
    "    for w in words:\n",
    "        bag.append(1) if w in pattern_words else bag.append(0)\n",
    "\n",
    "    training.append(bag)\n",
    "    # output is a '0' for each tag and '1' for current tag\n",
    "    output_row = list(output_empty)\n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "    output.append(output_row)\n",
    "    \n",
    "print (\"# words\", len(words))\n",
    "print (\"# classes\", len(classes))\n",
    "print (training[1])\n",
    "print (output[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# compute sigmoid nonlinearity\n",
    "def sigmoid(x):\n",
    "    output = 1/(1+np.exp(-x))\n",
    "    return output\n",
    "\n",
    "# convert output of sigmoid function to its derivative\n",
    "# if derivative/slope is small, then we are getting closer to the correct weight\n",
    "# if it is large, then we multiply by the large number to get a wildly different weight\n",
    "# we do this until we reach convergence\n",
    "def sigmoid_output_to_derivative(output):\n",
    "    return output*(1-output)\n",
    " \n",
    "def clean_up_sentence(sentence):\n",
    "    # tokenize the pattern\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    # stem each word\n",
    "    sentence_words = [stemmer.stem(word.lower()) for word in sentence_words]\n",
    "    return sentence_words\n",
    "\n",
    "# return bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n",
    "def bow(sentence, words, show_details=False):\n",
    "    # tokenize the pattern\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    # bag of words\n",
    "    bag = [0]*len(words)  \n",
    "    for s in sentence_words:\n",
    "        for i,w in enumerate(words):\n",
    "            if w == s: \n",
    "                bag[i] = 1\n",
    "                if show_details:\n",
    "                    print (\"found in bag: %s\" % w)\n",
    "\n",
    "    return(np.array(bag))\n",
    "\n",
    "def think(sentence, show_details=False):\n",
    "    x = bow(sentence.lower(), words, show_details)\n",
    "    if show_details:\n",
    "        print (\"sentence:\", sentence, \"\\n bow:\", x)\n",
    "    # input layer is our bag of words\n",
    "    l0 = x\n",
    "    # matrix multiplication of input and hidden layer\n",
    "    l1 = sigmoid(np.dot(l0, synapse_0))\n",
    "    # output layer\n",
    "    l2 = sigmoid(np.dot(l1, synapse_1))\n",
    "    return l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our Neural Network with Gradient Descent\n",
    "def train(X, y, hidden_neurons=10, alpha=1, epochs=50000, dropout=False, dropout_percent=0.5):\n",
    "\n",
    "    print (\"Training with %s neurons, alpha:%s, dropout:%s %s\" % (hidden_neurons, str(alpha), dropout, dropout_percent if dropout else '') )\n",
    "    print (\"Input matrix: %sx%s    Output matrix: %sx%s\" % (len(X),len(X[0]),1, len(classes)) )\n",
    "    np.random.seed(1)\n",
    "\n",
    "    last_mean_error = 1\n",
    "    # randomly initialize our weights with mean 0\n",
    "    synapse_0 = 2*np.random.random((len(X[0]), hidden_neurons)) - 1\n",
    "    synapse_1 = 2*np.random.random((hidden_neurons, len(classes))) - 1\n",
    "\n",
    "    prev_synapse_0_weight_update = np.zeros_like(synapse_0)\n",
    "    prev_synapse_1_weight_update = np.zeros_like(synapse_1)\n",
    "\n",
    "    synapse_0_direction_count = np.zeros_like(synapse_0)\n",
    "    synapse_1_direction_count = np.zeros_like(synapse_1)\n",
    "        \n",
    "    for j in iter(range(epochs+1)):\n",
    "\n",
    "        # Feed forward through layers 0, 1, and 2\n",
    "        layer_0 = X\n",
    "        layer_1 = sigmoid(np.dot(layer_0, synapse_0))\n",
    "                \n",
    "        if(dropout):\n",
    "            layer_1 *= np.random.binomial([np.ones((len(X),hidden_neurons))],1-dropout_percent)[0] * (1.0/(1-dropout_percent))\n",
    "\n",
    "        layer_2 = sigmoid(np.dot(layer_1, synapse_1))\n",
    "\n",
    "        # how much did we miss the target value?\n",
    "        layer_2_error = y - layer_2\n",
    "\n",
    "        if (j% 10000) == 0 and j > 5000:\n",
    "            # if this 10k iteration's error is greater than the last iteration, break out\n",
    "            if np.mean(np.abs(layer_2_error)) < last_mean_error:\n",
    "                print (\"delta after \"+str(j)+\" iterations:\" + str(np.mean(np.abs(layer_2_error))) )\n",
    "                last_mean_error = np.mean(np.abs(layer_2_error))\n",
    "            else:\n",
    "                print (\"break:\", np.mean(np.abs(layer_2_error)), \">\", last_mean_error )\n",
    "                break\n",
    "                \n",
    "        # in what direction is the target value?\n",
    "        # were we really sure? if so, don't change too much.\n",
    "        layer_2_delta = layer_2_error * sigmoid_output_to_derivative(layer_2)\n",
    "\n",
    "        # how much did each l1 value contribute to the l2 error (according to the weights)?\n",
    "        layer_1_error = layer_2_delta.dot(synapse_1.T)\n",
    "\n",
    "        # in what direction is the target l1?\n",
    "        # were we really sure? if so, don't change too much.\n",
    "        layer_1_delta = layer_1_error * sigmoid_output_to_derivative(layer_1)\n",
    "        \n",
    "        synapse_1_weight_update = (layer_1.T.dot(layer_2_delta))\n",
    "        synapse_0_weight_update = (layer_0.T.dot(layer_1_delta))\n",
    "        \n",
    "        if(j > 0):\n",
    "            synapse_0_direction_count += np.abs(((synapse_0_weight_update > 0)+0) - ((prev_synapse_0_weight_update > 0) + 0))\n",
    "            synapse_1_direction_count += np.abs(((synapse_1_weight_update > 0)+0) - ((prev_synapse_1_weight_update > 0) + 0))        \n",
    "        \n",
    "        synapse_1 += alpha * synapse_1_weight_update\n",
    "        synapse_0 += alpha * synapse_0_weight_update\n",
    "        \n",
    "        prev_synapse_0_weight_update = synapse_0_weight_update\n",
    "        prev_synapse_1_weight_update = synapse_1_weight_update\n",
    "\n",
    "    now = datetime.datetime.now()\n",
    "\n",
    "    # persist synapses\n",
    "    synapse = {'synapse0': synapse_0.tolist(), 'synapse1': synapse_1.tolist(),\n",
    "               'datetime': now.strftime(\"%Y-%m-%d %H:%M\"),\n",
    "               'words': words,\n",
    "               'classes': classes\n",
    "              }\n",
    "    synapse_file = \"synapses.json\"\n",
    "\n",
    "    with open(synapse_file, 'w') as outfile:\n",
    "        json.dump(synapse, outfile, indent=4, sort_keys=True)\n",
    "    print (\"saved synapses to:\", synapse_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 20 neurons, alpha:0.1, dropout:False \n",
      "Input matrix: 53x468    Output matrix: 1x4\n",
      "delta after 10000 iterations:0.0029424212851607494\n",
      "delta after 20000 iterations:0.0020143441694205114\n",
      "delta after 30000 iterations:0.0016163873082393424\n",
      "delta after 40000 iterations:0.0013832183855518015\n",
      "delta after 50000 iterations:0.0012259187407157317\n",
      "delta after 60000 iterations:0.0011108189049476112\n",
      "delta after 70000 iterations:0.0010220235904695606\n",
      "delta after 80000 iterations:0.0009509273022715216\n",
      "delta after 90000 iterations:0.0008924080869240321\n",
      "delta after 100000 iterations:0.0008431980054805808\n",
      "saved synapses to: synapses.json\n",
      "processing time: 22.473774194717407 seconds\n"
     ]
    }
   ],
   "source": [
    "X = np.array(training)\n",
    "y = np.array(output)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "train(X, y, hidden_neurons=20, alpha=0.1, epochs=100000, dropout=False, dropout_percent=0.2)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print (\"processing time:\", elapsed_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part numbers are not specified for the lighting fixtures \n",
      " Construction Topic/Cost Code: [['Electrical', 0.9600650143462094]] \n",
      "\n",
      "need another coat of paint and primer, please approve for additional cost \n",
      " Construction Topic/Cost Code: [['Finishes', 0.9580210624552732]] \n",
      "\n",
      "what brick type and color should we use \n",
      " Construction Topic/Cost Code: [['Masonry', 0.9962248304218728]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test our model\n",
    "\n",
    "# load our calculated synapse values\n",
    "# these are the final weights that we will use for predictions\n",
    "synapse_file = 'synapses.json' \n",
    "with open(synapse_file) as data_file: \n",
    "    synapse = json.load(data_file) \n",
    "    synapse_0 = np.asarray(synapse['synapse0']) \n",
    "    synapse_1 = np.asarray(synapse['synapse1'])\n",
    "\n",
    "# Only return results that have a probability greater than 0.15 (15%)\n",
    "# convert numerical representation of class into string and print result\n",
    "def classify(sentence, show_details=False):\n",
    "    results = think(sentence, show_details)\n",
    "\n",
    "    results = [[i,r] for i,r in enumerate(results) if r > .15 ] \n",
    "    results.sort(key=lambda x: x[1], reverse=True) \n",
    "    return_results =[[classes[r[0]],r[1]] for r in results]\n",
    "    print (\"%s \\n Construction Topic/Cost Code: %s \\n\" % (sentence, return_results))\n",
    "    #return return_results\n",
    "\n",
    "\n",
    "classify(\"Part numbers are not specified for the lighting fixtures\")\n",
    "classify(\"need another coat of paint and primer, please approve for additional cost\")\n",
    "classify(\"what brick type and color should we use\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
